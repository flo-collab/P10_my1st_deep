{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intuitions on Convolutions\n",
    "\n",
    "Let's build intuitions about these **`convolution operations`**.\n",
    "\n",
    "**Goals**\n",
    "- `Compute` convolution operations\n",
    "- `Visualize` \n",
    "    - convolution kernels\n",
    "    - the effects of a convolution kernel applied on images\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Convolutional Neural Networks are Neural Networks specifically designed to work on images**. \n",
    "\n",
    "This is made possible thanks to **`convolutions`**.\n",
    "\n",
    "These specific mathematical operations apply a **`kernel`** to an input image and creates an output representation. The name of this **`output`** can change depending on the community. Here, let's talk about the output as the **`output of a layer`**, as in standard NN models. But for CNNs, it can also be called :\n",
    "* a **`\"convoluted representation/feature\"`**,\n",
    "* or a **`\"convolution\"`**,\n",
    "* or also an **`\"activation\"`** (as it corresponds to the activation of a given layer).\n",
    "\n",
    "<img src=\"convolution.png\" width=\"300\">\n",
    "\n",
    "‚ö†Ô∏è It is important to understand that **the same kernel, i.e. the same weights, are applied to different zones of the images**. \n",
    "\n",
    "‚ö†Ô∏è This is completely different from Dense Neural Networks that we've been working with.\n",
    "* Indeed, in `Dense/\"Fully Connected\" Neural Network`, each weight of each neuron is related to only one input coordinate (which in this case would be each pixel).\n",
    "* Here in a `Convolution Neural Network`, the weights of a kernel are not applied to only one input, i.e. one pixel, but to different pixels, \"step by step\" !\n",
    "\n",
    "üëâ You can think of each kernel (or each filter in the case of colored images) as a **`magnifying glass`** through which you see the image. Similarly to your eyes, kernels cannot capture everything in a picture at once, but they ***scan different parts of a picture before understanding the whole picture which is being analyzed***.\n",
    "\n",
    "üé¨ So let's have a closer look at `convolution operations`, and their impact in `Convolutional Neural Networks`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "‚ùì First use the following function to load the data:\n",
    "\n",
    "‚ö†Ô∏è Do not change anything !\n",
    "\n",
    "‚ö†Ô∏è Restrict from any desire to change the shapes or types of the outputs! This will have an impact on further questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib.pyplot import imread\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def load_data(path):\n",
    "    nb_circles = 100\n",
    "    nb_triangles = 100\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(nb_circles):\n",
    "        c_path = os.path.join(path, 'circles', f'circle_{i}.png')\n",
    "        X.append(imread(c_path)[:, :, :1])\n",
    "        y.append(0)\n",
    "    \n",
    "    for i in range(nb_triangles):\n",
    "        t_path = os.path.join(path, 'triangles', f'triangle_{i}.png')\n",
    "        X.append(imread(t_path)[:, :, :1])\n",
    "        y.append(1)\n",
    "        \n",
    "    c = list(zip(X, y))\n",
    "    np.random.shuffle(c)\n",
    "    X, y = zip(*c)\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "        \n",
    "X, y = load_data(\"data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Check the shape of your data. Especially, why an additional dimension of size 1 for X?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Do the input images need some normalization? ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Display some images with `plt.imshow` and their respective labels (the images are black and white, therefore use `cmap=gray` in the dedicated matplotlib function - otherwise, you will get unrelevant and weird colors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì How many classes are we going to predict are there? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Kernels\n",
    "\n",
    "The following function performs a **`convolution operation`**, i.e. **it applies a kernel to an image**.\n",
    "\n",
    "‚ö†Ô∏è Be careful ! \n",
    "* A \"_convolution_ operation\" in CNN is different from a \"_convolution_ operation\" in Signal Preprocessing. \n",
    "* For instance, the `numpy.convolve` function does NOT compute the convolution in the Deep Learning - CNN sense.\n",
    "\n",
    "‚ö†Ô∏è Another warning, this `compute_convolution` is simplified:\n",
    "* Convolutions are a bit more complex as they also involve `padding` and `strides`. \n",
    "\n",
    "‚ö†Ô∏è Vocabulary: \n",
    "* \"Convolution\" sometimes refers to _one_ operation. \n",
    "* It can also refer to the  convolution operations repeated on the entire image.\n",
    "* When you are dealing with convolutions, make sure to align with your classmates/colleagues on what you are talking about.\n",
    "\n",
    "‚ùì Load the function and go through the lines to understand what it is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_convolution(img, kernel):\n",
    "    # Parameters\n",
    "    kernel = np.array(kernel)\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "\n",
    "    img = np.squeeze(img) # Removes dimensions of size 1\n",
    "    img_height, img_width = img.shape\n",
    "    \n",
    "    array = []\n",
    "\n",
    "    for x in range(img_height-kernel_height):\n",
    "        arr = []\n",
    "        \n",
    "        for y in range(img_width - kernel_width):\n",
    "            \n",
    "            a = np.multiply(img[x:x+kernel_height, y:y+kernel_width], kernel)\n",
    "            arr.append(a.sum())\n",
    "            \n",
    "        array.append(arr)\n",
    "        \n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Apply the `compute_convolution`  with the following kernel to any image from the input dataset. \n",
    "\n",
    "* Display both the input image and output image\n",
    "* Do you see differences ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_kernel = [\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 0]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous kernel corresponds to the **`identity_ kernel`**, meaning that the output is equal to the input... It basically does nothing to the input image. You can easily figure this out by thinking about the operation it does on the image : only one pixel per convolution operation is kept as the other are multiplied by 0.\n",
    "\n",
    "‚ùì `plot_convolution` with the following `kernel_1`, once on an triangle and once on a circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_1 = [\n",
    "    [1, 1, 1],\n",
    "    [0, 0, 0],\n",
    "    [-1, -1, -1]\n",
    "]\n",
    "\n",
    "def plot_convolution(img, kernel, activation=False):\n",
    "    ''' The following printing function ease the visualization'''\n",
    "    \n",
    "    img = np.squeeze(img)\n",
    "    output_img = compute_convolution(img, kernel)\n",
    "    if activation:\n",
    "        output_img = np.maximum(output_img, 0)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    ax1 = plt.subplot2grid((3,3),(0,0), rowspan=3)\n",
    "    ax1.imshow(img, cmap='gray')\n",
    "    ax1.title.set_text('Input image')\n",
    "    \n",
    "    ax2 = plt.subplot2grid((3,3),(1, 1))\n",
    "    ax2.imshow(kernel, cmap='gray')\n",
    "    ax2.title.set_text('Kernel')    \n",
    "    \n",
    "    ax3 = plt.subplot2grid((3,3),(0, 2), rowspan=3)\n",
    "    ax3.imshow(output_img, cmap='gray')\n",
    "    ax3.title.set_text('Output image')    \n",
    "\n",
    "    for ax in [ax1, ax2, ax3]:\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "‚ùì Let's try to understand why this is meaningful. First, white colors correspond to high values and black to low values. In a neural network, just after a regular neuron or a convolution, there is an activation function. When the activation function is a relu, it just correponds to setting the negative values to 0.\n",
    "\n",
    "Well, let's see what it means in the case of a CNN. Re-run the previous functions with activation set to True (in this case, the activation fuction is the relu).."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì This kernel is actually highlighting the edges in a given direction. \n",
    "\n",
    "* Try the following kernels to check the different edges it can detect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_2 = [\n",
    "    [-1, -1, -1],\n",
    "    [0, 0, 0],   \n",
    "    [1, 1, 1],\n",
    "]\n",
    "\n",
    "kernel_3 = [\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0, 1]\n",
    "]\n",
    "\n",
    "kernel_4 = [\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1]\n",
    "]\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **What is the `effect of kernel size`**? \n",
    "\n",
    "üëá Check it out with a larger kernel of shape (10,10) down below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_big = np.array([\n",
    "    np.ones((10,)),\n",
    "    np.ones((10,)),\n",
    "    np.ones((10,)),\n",
    "    np.zeros((10,)),\n",
    "    np.zeros((10,)),\n",
    "    np.zeros((10,)),\n",
    "    np.zeros((10,)),\n",
    "    np.ones((10,))*-1,\n",
    "    np.ones((10,))*-1,\n",
    "    np.ones((10,))*-1,\n",
    "])\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Feel free to try any other kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_kernel = np.random.uniform(-10, 10, (5, 5))\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've got the idea of what a convolution operation does to an image, let's see how it goes with a \"real\" Convolutional Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Convolutional Neural Network\n",
    "\n",
    "\n",
    "‚ùì Write a convolutional network that has \n",
    "- a Convolutional Layer with 16 filters with (4, 4) kernels.\n",
    "- a Convolutional Layer with 32 filters with (3, 3) kernels.\n",
    "- a Convolutional Layer with 32 filters with (3, 3) kernels.\n",
    "- a Convolutional Layer with 32 filters with (2, 2) kernels.\n",
    "\n",
    "with:\n",
    "- A Max-Pooling Layer (with a (2, 2) pool-size) after each convolution.\n",
    "- A Hidden Dense Layer with the size of your choice, be reasonable:\n",
    "    - after the flattening part \n",
    "    - but before the last layer\n",
    "\n",
    "\n",
    "Also, make sure to compile your model with the adequate parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "# YOUR CODE HERE\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "‚ùì Fit the model. You should achieve a accuracy of at least 90. Here, the point is not to bother with overfitting, so do not worry much as you would have to if you have a high score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî• It is possible to **`retrieve the values of the different kernels in the CNN`**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëç First, remember that for a Sequential Neural Network (Convolutional or Dense), you can:\n",
    "- print the `.summary()` to display the layers and the number of weights/parameters involved\n",
    "- access the differents `.layers` of your model\n",
    "\n",
    "‚ùì Print the different layers of your CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Print the summary of your CNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì\n",
    "Have a look at the following method that returns the `values/weights of a kernel` depending on:\n",
    "- the `layer number`, \n",
    "    - which can be only `0 `, `2`, `4` or `6` as , as we used 4 `Conv2D - convolutional layers`, each of them followed by a `MaxPool2D` layer\n",
    "- the `kernel number`\n",
    "- the `channel number`\n",
    "\n",
    "With the following table, you will have a better overview of the different weights, kernels and filters involved in the CNN you've built earlier:\n",
    "\n",
    "| layer_number | convolution_layer | kernel_number | channel_number |\n",
    "|--------------|-------------------|---------------|----------------|\n",
    "| 0            | conv2D no 1       | 16            | 1              |\n",
    "| 2            | conv2D no 2       | 32            | 16             |\n",
    "| 4            | conv2D no 3       | 64            | 32             |\n",
    "| 8            | conv2D no 4       | 64            | 64             |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "‚ùì  Using **`plot_convolution(activation=True)`**, display some kernels from the FIRST convolutional layer, along with the activation output, to see what the model has learnt from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [],
   "source": [
    "# First Conv2D Layer --> 16 kernels - 4x4 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [],
   "source": [
    "# Second Conv2D Layer --> 32 kernels - 3x3 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [],
   "source": [
    "# Third Conv2D Layer --> 64 kernels - 3x3 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [],
   "source": [
    "# Fourth/Last Conv2D Layer --> 64 kernels - 2x2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "source": [
    "We can also inspect the number of weights involved in our Dense layers üëá:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [],
   "source": [
    "# Weights and biases of the hidden Dense layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [],
   "source": [
    "# Weights and biases of the prediction dense layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "source": [
    "But let's focus our attention on the **`convolutional layers`** a.k.a. **`Conv2D`** !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel(layer_number, kernel_number, channel_number):\n",
    "\n",
    "    weight_or_bias = 0\n",
    "    k = model.layers[layer_number].weights[0].numpy()[:,\n",
    "                                                      :,\n",
    "                                                      channel_number,\n",
    "                                                      kernel_number]\n",
    "\n",
    "    return k\n",
    "\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      " \n",
      " \n",
      "The original picture had 1 channel...\n",
      "... and we created 16 outputs using 16 kernels...\n",
      "What are the outputs of those 16 kernels applied to our image ?\n",
      " \n",
      " \n",
      "------------------------- Effect of the kernel number 0 -------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-0a863d9c9c9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"------------------------- Effect of the kernel number {i} -------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mplot_convolution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-b6dccce92581>\u001b[0m in \u001b[0;36mget_kernel\u001b[1;34m(layer_number, kernel_number, channel_number)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mweight_or_bias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     k = model.layers[layer_number].weights[0].numpy()[:,\n\u001b[0m\u001b[0;32m      5\u001b[0m                                                       \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                                       \u001b[0mchannel_number\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 81)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "print(\"The original picture had 1 channel...\")\n",
    "print(\"... and we created 16 outputs using 16 kernels...\")\n",
    "print(\"What are the outputs of those 16 kernels applied to our image ?\")\n",
    "\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "for i in np.arange(0,16):\n",
    "    print(f\"------------------------- Effect of the kernel number {i} -------------------------\")\n",
    "    kernel = get_kernel(0, i, 0)\n",
    "    plot_convolution(X[1], kernel, activation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* üëÄ We have been looking at the activation (\"`output image`\") of the **first layer** only.\n",
    "\n",
    "\n",
    "* ü§î What if we want to **visualize the activation of the CNN after the second convolutional layer** ?\n",
    "    1. We need to compute the activations after the first layer, \n",
    "    2. then run the MaxPooling operation\n",
    "    3. and eventually the  second convolution operations\n",
    "    \n",
    "  ü•µ Quite a tedious process, right ?\n",
    "\n",
    "üòá Have a look at the cell down below, we provided you with a **`function to retrieve an activation`** based on :\n",
    "* the *`image_number`*\n",
    "* the *`layer_number`*\n",
    "* the *`kernel_number`*\n",
    "\n",
    "üéÅ It computes the different activations through the entire network and store them in a list\n",
    "\n",
    "üí° *Remark*: It uses the  `tensorflow.keras` `Fonctional API` syntax!\n",
    "\n",
    "‚ùì Run the following cells step by step:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1 : list all the layers' outputs of your CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the layers outputs\n",
    "#layers_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are `4 (Conv2D, MaxPooling2D)` couples which represent $ 4 \\times 2 = 8 $ layers\n",
    "* Followed by :\n",
    "    * a `Flatten Layer`\n",
    "    * a `Hidden Layer`\n",
    "    * a `Prediction Layer`\n",
    "    \n",
    "In total, we have 11 layers, hence 11 layers' outputs.\n",
    "\n",
    "Among these 11 layers, 4 are Convolutional Layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(layers_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Instantiate 11 sub-models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate 11 sub-models: [layer1, layer1-->layer2, layer1-->layer2-->layer3, ...]\n",
    "# Re-using already trained weights and biases\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Compute the outputs of each submodel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the 11 outputs of each sub-model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's wrap this process into a `get_activation` function** !\n",
    "\n",
    "üéÅ We already wrote the function for you: this function helps you get the activation after any layer, based on :\n",
    "* the `image_number` of the dataset\n",
    "* the `layer_number`\n",
    "* the `kernel_number`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(activations, image_number, layer_number, kernel_number):\n",
    "    '''return activation map for a given layer, image, and kernel number'''\n",
    "    return activations[layer_number][image_number][:, :, kernel_number]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Questions** ‚ùì \n",
    "\n",
    "* Choose one image\n",
    "* Display the activation \"images\" of each convolutional layer. \n",
    "    * Pick for instance the first kernel of each convolutional layer. \n",
    "    \n",
    "***Notes***\n",
    "1. Notice how the information of an image **flows** through the Convolutional Neural Network.\n",
    "2. You should see the picture becoming more and more \"abstract\", of smaller and smaller \"dimensions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "#Displayer layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 200 images: 100 triangles and 100 circles\n"
     ]
    }
   ],
   "source": [
    "print(f\"We have {len(X)} images: 100 triangles and 100 circles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [],
   "source": [
    "#plt.imshow(activation, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Observing the effect of the convolution layer number 1... ---\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-ed5c0fd45380>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"--- Observing the effect of the convolution layer number {convolution_layer_number}... ---\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtemp_number_kernels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer_number\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{temp_number_kernels} kernels were applied and here are all the activations of this Conv2d Layer:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "image_number = 3\n",
    "\n",
    "convolution_layer_number = 1\n",
    "\n",
    "for layer_number in [0,2,4,6]:\n",
    "    print(f\"--- Observing the effect of the convolution layer number {convolution_layer_number}... ---\")\n",
    "    print(\"\")\n",
    "    temp_number_kernels = model.layers[layer_number].weights[0].shape[-1]\n",
    "    print(f\"{temp_number_kernels} kernels were applied and here are all the activations of this Conv2d Layer:\")\n",
    "    \n",
    "    fig, axes = plt.subplots(int(temp_number_kernels/4),4, figsize=(20,7))\n",
    "    \n",
    "    \n",
    "    for ax, kernel_number in zip(axes.flat,range(temp_number_kernels)):\n",
    "        activation = get_activation(activations, \n",
    "                                    image_number=image_number, \n",
    "                                    layer_number=layer_number, \n",
    "                                    kernel_number=kernel_number)\n",
    "        ax.imshow(activation, cmap=\"gray\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    convolution_layer_number += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ **Congratulations!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils (Appendix)\n",
    "\n",
    "* The following section simply presents the functions that helped us create the dataset with triangles and circles you have been working with.\n",
    "\n",
    "* They were left at the end of the notebook just in case you want to further prototype and get better understanding of what is going on. \n",
    "\n",
    "* But skip this section and go to the next exercise as for now, and come back to it any time later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_triangle():\n",
    "    dx = np.random.uniform(0.1, 0.3)\n",
    "    dy = np.random.uniform(0.1, 0.3)\n",
    "    noise_x = np.random.uniform(0.0, 0.1)\n",
    "    noise_y = np.random.uniform(0.0, 0.1)    \n",
    "    \n",
    "    x = np.random.uniform(0, 1-dx-noise_x)\n",
    "    y = np.random.uniform(0, 1-dy)\n",
    "    X = np.array([[x,y], [x+dx+noise_x,y], [x+dx/2, y+dy+noise_y]])\n",
    "\n",
    "    t1 = plt.Polygon(X, color='black')\n",
    "    plt.gca().add_patch(t1)\n",
    "    \n",
    "def draw_circle():\n",
    "    r = np.random.uniform(0.1, 0.25)\n",
    "    x = np.random.uniform(0+r, 1-r)\n",
    "    y = np.random.uniform(0+r, 1-r)\n",
    "\n",
    "    circle1 = plt.Circle((x, y), r, color='black')\n",
    "    plt.gcf().gca().add_artist(circle1)\n",
    "    \n",
    "def create_image(form, path):\n",
    "    plt.figure(figsize=(1, 1))\n",
    "    if form == 'circle':\n",
    "        draw_circle()\n",
    "    elif form == 'triangle':\n",
    "        draw_triangle()\n",
    "    plt.axis('off')\n",
    "    plt.savefig(path, dpi=80, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "def create_images(path):\n",
    "    nb_circles = 100\n",
    "    nb_triangles = 100\n",
    "    \n",
    "    for i in range(nb_circles):\n",
    "        c_path = os.path.join(path, 'circles', f'circle_{i}.png')\n",
    "        create_image('circle', c_path)\n",
    "        \n",
    "    for i in range(nb_triangles):\n",
    "        t_path = os.path.join(path, 'triangles', f'triangle_{i}.png')\n",
    "        create_image('triangle', t_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
